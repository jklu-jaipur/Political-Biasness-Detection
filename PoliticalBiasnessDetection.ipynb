{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If packages are not found then use: pip install package_name'''\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre processing and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataPreProcessing:\n",
    "    def __init__(self,path):\n",
    "        self.data=pd.read_csv(path,delimiter = \",\")\n",
    "        self.data.columns = ((self.data.columns.str).replace(\"^ \",\"\")).str.replace(\" $\",\"\")   #removing cloumns spaces\n",
    "        self.data[\"Article\"].fillna(\"To be added\", inplace = True)\n",
    "        self.data[\"Headline\"].fillna(\"To be added\", inplace = True)       #replacing NaN values with some text\n",
    "        self.data[\"Label\"].fillna(\"To be added\", inplace = True)\n",
    "        self.data[\"Publisher\"].fillna(\"To be added\", inplace = True)\n",
    "    def read_data(self):\n",
    "        return self.data\n",
    "    def clean_article(self,article):\n",
    "        article=article.lower()\n",
    "        article = re.sub('\\[.*?\\]', '', article)\n",
    "        article = re.sub('[%s]' % re.escape(string.punctuation), '', article)\n",
    "        article = re.sub('\\w*\\d\\w*', '', article)\n",
    "        return article\n",
    "    def clean_dataset(self):\n",
    "        for i in range(len(self.data)):\n",
    "            self.data['Article'][i]=self.clean_article(self.data['Article'][i])\n",
    "            self.data['Headline'][i]=self.clean_article(self.data['Headline'][i])\n",
    "            self.data['Label'][i]=self.data['Label'][i].lower()\n",
    "        return self.data\n",
    "    def tokenize(self):\n",
    "        pass\n",
    "    def remove_stopwords(self):\n",
    "        pass\n",
    "        \n",
    "data = dataPreProcessing('data/data.csv')\n",
    "#print(data.read_data()['Article'][0])              # for comparison of articles\n",
    "#data.read_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jammu and kashmir has been a theatre of muscular hindutva nationalism in the early decades in script and since  in performance adopting a highly militarist approach to separatism and shunning political process entirely since  the bjp has now delivered on a promise it has long made by abrogating the special status that jammu and kashmir had enjoyed in the constitution through a combination of executive and parliamentary measures additionally the state is being downgraded and divided into two union territories the mechanism that the government used to railroad its rigid ideological position on jammu and kashmir through the rajya sabha was both hasty and stealthy this move will strain indias social fabric not only in its impact on jammu and kashmir but also in the portents it holds for federalism parliamentary democracy and diversity the bjpled government has undermined parliamentary authority in multiple ways since  but the passing of legislation as farreaching as dismembering a state without prior consultations has set a new low the founding fathers of the republic favoured a strong centre but they were also prudent in seeking the route of persuasion and accommodation towards linguistic and religious minorities in the interest of national integration the centralising tendencies increased in the following decades but hindu nationalists always argued for stronger unitary provisions and viewed all particular aspirations with suspicion for them jammu and kashmirs special constitutional status was an impediment not an instrument for the regions integration with the rest of the country\r\n",
      " \r\n",
      "the entire exercise of getting article  of the constitution effectively abrogated has been marked by executive excess the first step was to declare by a presidential decree that the governor  without regard to the fact that he has no council of ministers now to aid and advise him  can speak for the state government and give his concurrence to any modification in the way the constitution of india applies to jammu and kashmir second on the basis of this concurrence the latest presidential order scraps the previous one of  abrogating the separate constitution of jammu and kashmir third the fact that the state is under presidents rule has been used to usher in a new dispensation under which jammu and kashmir becomes a union territory with a legislature and ladakh another such territory without a legislature in sum a purported process to change the constitutional status of a sensitive border state has been achieved without any legislative input or representative contribution from its people the bifurcation of states in the past cannot be cited as a binding precedent as under article  of the constitution the president seeks the views of the legislature of the states concerned even if concurrence is not mandatory in the present scenario jk has been represented by an unelected governor appointed by the centre while parliament has ventured to ratify the conversion of a state into two union territories without any recommendation from the state\r\n",
      "\r\n",
      "if there is a legal challenge to these measures it would centre around whether such farreaching steps could be achieved in the absence of a representative government by assuming that its gubernatorial administrator is constitutionally capable of using his consent as that of the entire state further there is a selfenabling aspect to the presidential order it performs a hopstepandjump feat it hops over the requirement of the state governments consent by declaring that the governor is the state government it steps over the need for aid and advice by the ministerial council by saying the governors opinion is enough and it jumps over the fact that there is no constituent assembly now by merely reading the term as legislative assembly and letting parliament perform the role of the state legislature thus the presidents power under article  has been used both to create an enabling provision and to exercise it immediately to modify the order thereby dispensing with the role envisaged for the state assembly while it is true that in  the supreme court upheld the presidents power to modify the constitutional provisions in applying them to jk it is a moot question whether this can be invoked to make such a radical change a functioning state has now been downgraded and bifurcated into two union territories it is inconceivable that any state legislature would ever have recommended its own demotion in status\r\n",
      "\r\n",
      "\r\n",
      "true the special status of jk was meant to end but only with the concurrence of its people the centres abrupt move disenfranchised them on a matter that directly affected their life and sentiments moreover that this was done after a massive military buildup and the house arrest of senior political leaders and the communications shutdown reveals a cynical disregard of democratic norms it appears that the current government values jk for its demonstrative impact before the rest of the country as a place where a strong nation and its strong leader show uncompromising political will but that may have other unintended consequences geographically and metaphorically jammu and kashmir is the crown of secular india  a muslim majority region in a hindu majority country its people and leaders had chosen secular india over islamic pakistan a fact that islamists never reconciled with the bjps adventurous route also has as backdrop an impending us withdrawal from afghanistan that will trigger an unforeseeable churn in islamist politics in the region islamists have always viewed kashmir as a component of their global grievances whatever its intent in enabling the full integration of jammu and kashmir with india mondays decision to alter the states status could have unintended and dangerous consequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df=data.clean_dataset()['Article'][0]    #for comparison of articles\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing, Lemmatizing, and removing stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "tokens=word_tokenize(df)\n",
    "#print(tokens)\n",
    "wordsInArticle= len(tokens)\n",
    "print(wordsInArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jammu', 'kashmir', 'theatre', 'muscular', 'hindutva', 'nationalism', 'early', 'decades', 'script', 'since', 'performance', 'adopting', 'highly', 'militarist', 'approach', 'separatism', 'shunning', 'political', 'process', 'entirely', 'since', 'bjp', 'delivered', 'promise', 'long', 'made', 'abrogating', 'special', 'status', 'jammu', 'kashmir', 'enjoyed', 'constitution', 'combination', 'executive', 'parliamentary', 'measures', 'additionally', 'state', 'downgraded', 'divided', 'two', 'union', 'territories', 'mechanism', 'government', 'used', 'railroad', 'rigid', 'ideological', 'position', 'jammu', 'kashmir', 'rajya', 'sabha', 'hasty', 'stealthy', 'move', 'strain', 'indias', 'social', 'fabric', 'impact', 'jammu', 'kashmir', 'also', 'portents', 'holds', 'federalism', 'parliamentary', 'democracy', 'diversity', 'bjpled', 'government', 'undermined', 'parliamentary', 'authority', 'multiple', 'ways', 'since', 'passing', 'legislation', 'farreaching', 'dismembering', 'state', 'without', 'prior', 'consultations', 'set', 'new', 'low', 'founding', 'fathers', 'republic', 'favoured', 'strong', 'centre', 'also', 'prudent', 'seeking', 'route', 'persuasion', 'accommodation', 'towards', 'linguistic', 'religious', 'minorities', 'interest', 'national', 'integration', 'centralising', 'tendencies', 'increased', 'following', 'decades', 'hindu', 'nationalists', 'always', 'argued', 'stronger', 'unitary', 'provisions', 'viewed', 'particular', 'aspirations', 'suspicion', 'jammu', 'kashmirs', 'special', 'constitutional', 'status', 'impediment', 'instrument', 'regions', 'integration', 'rest', 'country', 'entire', 'exercise', 'getting', 'article', 'constitution', 'effectively', 'abrogated', 'marked', 'executive', 'excess', 'first', 'step', 'declare', 'presidential', 'decree', 'governor', 'without', 'regard', 'fact', 'council', 'ministers', 'aid', 'advise', 'speak', 'state', 'government', 'give', 'concurrence', 'modification', 'way', 'constitution', 'india', 'applies', 'jammu', 'kashmir', 'second', 'basis', 'concurrence', 'latest', 'presidential', 'order', 'scraps', 'previous', 'one', 'abrogating', 'separate', 'constitution', 'jammu', 'kashmir', 'third', 'fact', 'state', 'presidents', 'rule', 'used', 'usher', 'new', 'dispensation', 'jammu', 'kashmir', 'becomes', 'union', 'territory', 'legislature', 'ladakh', 'another', 'territory', 'without', 'legislature', 'sum', 'purported', 'process', 'change', 'constitutional', 'status', 'sensitive', 'border', 'state', 'achieved', 'without', 'legislative', 'input', 'representative', 'contribution', 'people', 'bifurcation', 'states', 'past', 'cited', 'binding', 'precedent', 'article', 'constitution', 'president', 'seeks', 'views', 'legislature', 'states', 'concerned', 'even', 'concurrence', 'mandatory', 'present', 'scenario', 'jk', 'represented', 'unelected', 'governor', 'appointed', 'centre', 'parliament', 'ventured', 'ratify', 'conversion', 'state', 'two', 'union', 'territories', 'without', 'recommendation', 'state', 'legal', 'challenge', 'measures', 'would', 'centre', 'around', 'whether', 'farreaching', 'steps', 'could', 'achieved', 'absence', 'representative', 'government', 'assuming', 'gubernatorial', 'administrator', 'constitutionally', 'capable', 'using', 'consent', 'entire', 'state', 'selfenabling', 'aspect', 'presidential', 'order', 'performs', 'hopstepandjump', 'feat', 'hops', 'requirement', 'state', 'governments', 'consent', 'declaring', 'governor', 'state', 'government', 'steps', 'need', 'aid', 'advice', 'ministerial', 'council', 'saying', 'governors', 'opinion', 'enough', 'jumps', 'fact', 'constituent', 'assembly', 'merely', 'reading', 'term', 'legislative', 'assembly', 'letting', 'parliament', 'perform', 'role', 'state', 'legislature', 'thus', 'presidents', 'power', 'article', 'used', 'create', 'enabling', 'provision', 'exercise', 'immediately', 'modify', 'order', 'thereby', 'dispensing', 'role', 'envisaged', 'state', 'assembly', 'true', 'supreme', 'court', 'upheld', 'presidents', 'power', 'modify', 'constitutional', 'provisions', 'applying', 'jk', 'moot', 'question', 'whether', 'invoked', 'make', 'radical', 'change', 'functioning', 'state', 'downgraded', 'bifurcated', 'two', 'union', 'territories', 'inconceivable', 'state', 'legislature', 'would', 'ever', 'recommended', 'demotion', 'status', 'true', 'special', 'status', 'jk', 'meant', 'end', 'concurrence', 'people', 'centres', 'abrupt', 'move', 'disenfranchised', 'matter', 'directly', 'affected', 'life', 'sentiments', 'moreover', 'done', 'massive', 'military', 'buildup', 'house', 'arrest', 'senior', 'political', 'leaders', 'communications', 'shutdown', 'reveals', 'cynical', 'disregard', 'democratic', 'norms', 'appears', 'current', 'government', 'values', 'jk', 'demonstrative', 'impact', 'rest', 'country', 'place', 'strong', 'nation', 'strong', 'leader', 'show', 'uncompromising', 'political', 'may', 'unintended', 'consequences', 'geographically', 'metaphorically', 'jammu', 'kashmir', 'crown', 'secular', 'india', 'muslim', 'majority', 'region', 'hindu', 'majority', 'country', 'people', 'leaders', 'chosen', 'secular', 'india', 'islamic', 'pakistan', 'fact', 'islamists', 'never', 'reconciled', 'bjps', 'adventurous', 'route', 'also', 'backdrop', 'impending', 'us', 'withdrawal', 'afghanistan', 'trigger', 'unforeseeable', 'churn', 'islamist', 'politics', 'region', 'islamists', 'always', 'viewed', 'kashmir', 'component', 'global', 'grievances', 'whatever', 'intent', 'enabling', 'full', 'integration', 'jammu', 'kashmir', 'india', 'mondays', 'decision', 'alter', 'states', 'status', 'could', 'unintended', 'dangerous', 'consequences']\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "# removing stop-words\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    stopwordsInArticle=[]\n",
    "    stopwordsNotInArticle=[]\n",
    "    for i in tokens:\n",
    "        if i not in stopwords.words('english'):\n",
    "            stopwordsNotInArticle.append(i)\n",
    "        else:\n",
    "            stopwordsInArticle.append(i)\n",
    "    return stopwordsInArticle,stopwordsNotInArticle\n",
    "\n",
    "stopwordsInArticle,stopwordsNotInArticle=remove_stop_words(tokens)\n",
    "print(stopwordsNotInArticle)\n",
    "\n",
    "wordsInArticle= len(stopwordsNotInArticle)\n",
    "print(wordsInArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jammu', 'kashmir', 'theatre', 'muscular', 'hindutva', 'nationalism', 'early', 'decades', 'script', 'since', 'performance', 'adopt', 'highly', 'militarist', 'approach', 'separatism', 'shun', 'political', 'process', 'entirely', 'since', 'bjp', 'deliver', 'promise', 'long', 'make', 'abrogate', 'special', 'status', 'jammu', 'kashmir', 'enjoy', 'constitution', 'combination', 'executive', 'parliamentary', 'measure', 'additionally', 'state', 'downgrade', 'divide', 'two', 'union', 'territories', 'mechanism', 'government', 'use', 'railroad', 'rigid', 'ideological', 'position', 'jammu', 'kashmir', 'rajya', 'sabha', 'hasty', 'stealthy', 'move', 'strain', 'indias', 'social', 'fabric', 'impact', 'jammu', 'kashmir', 'also', 'portents', 'hold', 'federalism', 'parliamentary', 'democracy', 'diversity', 'bjpled', 'government', 'undermine', 'parliamentary', 'authority', 'multiple', 'ways', 'since', 'pass', 'legislation', 'farreaching', 'dismember', 'state', 'without', 'prior', 'consultations', 'set', 'new', 'low', 'found', 'father', 'republic', 'favour', 'strong', 'centre', 'also', 'prudent', 'seek', 'route', 'persuasion', 'accommodation', 'towards', 'linguistic', 'religious', 'minorities', 'interest', 'national', 'integration', 'centralise', 'tendencies', 'increase', 'follow', 'decades', 'hindu', 'nationalists', 'always', 'argue', 'stronger', 'unitary', 'provision', 'view', 'particular', 'aspirations', 'suspicion', 'jammu', 'kashmirs', 'special', 'constitutional', 'status', 'impediment', 'instrument', 'regions', 'integration', 'rest', 'country', 'entire', 'exercise', 'get', 'article', 'constitution', 'effectively', 'abrogate', 'mark', 'executive', 'excess', 'first', 'step', 'declare', 'presidential', 'decree', 'governor', 'without', 'regard', 'fact', 'council', 'minister', 'aid', 'advise', 'speak', 'state', 'government', 'give', 'concurrence', 'modification', 'way', 'constitution', 'india', 'apply', 'jammu', 'kashmir', 'second', 'basis', 'concurrence', 'latest', 'presidential', 'order', 'scrap', 'previous', 'one', 'abrogate', 'separate', 'constitution', 'jammu', 'kashmir', 'third', 'fact', 'state', 'presidents', 'rule', 'use', 'usher', 'new', 'dispensation', 'jammu', 'kashmir', 'become', 'union', 'territory', 'legislature', 'ladakh', 'another', 'territory', 'without', 'legislature', 'sum', 'purport', 'process', 'change', 'constitutional', 'status', 'sensitive', 'border', 'state', 'achieve', 'without', 'legislative', 'input', 'representative', 'contribution', 'people', 'bifurcation', 'state', 'past', 'cite', 'bind', 'precedent', 'article', 'constitution', 'president', 'seek', 'view', 'legislature', 'state', 'concern', 'even', 'concurrence', 'mandatory', 'present', 'scenario', 'jk', 'represent', 'unelected', 'governor', 'appoint', 'centre', 'parliament', 'venture', 'ratify', 'conversion', 'state', 'two', 'union', 'territories', 'without', 'recommendation', 'state', 'legal', 'challenge', 'measure', 'would', 'centre', 'around', 'whether', 'farreaching', 'step', 'could', 'achieve', 'absence', 'representative', 'government', 'assume', 'gubernatorial', 'administrator', 'constitutionally', 'capable', 'use', 'consent', 'entire', 'state', 'selfenabling', 'aspect', 'presidential', 'order', 'perform', 'hopstepandjump', 'feat', 'hop', 'requirement', 'state', 'governments', 'consent', 'declare', 'governor', 'state', 'government', 'step', 'need', 'aid', 'advice', 'ministerial', 'council', 'say', 'governors', 'opinion', 'enough', 'jump', 'fact', 'constituent', 'assembly', 'merely', 'read', 'term', 'legislative', 'assembly', 'let', 'parliament', 'perform', 'role', 'state', 'legislature', 'thus', 'presidents', 'power', 'article', 'use', 'create', 'enable', 'provision', 'exercise', 'immediately', 'modify', 'order', 'thereby', 'dispense', 'role', 'envisage', 'state', 'assembly', 'true', 'supreme', 'court', 'uphold', 'presidents', 'power', 'modify', 'constitutional', 'provision', 'apply', 'jk', 'moot', 'question', 'whether', 'invoke', 'make', 'radical', 'change', 'function', 'state', 'downgrade', 'bifurcate', 'two', 'union', 'territories', 'inconceivable', 'state', 'legislature', 'would', 'ever', 'recommend', 'demotion', 'status', 'true', 'special', 'status', 'jk', 'mean', 'end', 'concurrence', 'people', 'centre', 'abrupt', 'move', 'disenfranchise', 'matter', 'directly', 'affect', 'life', 'sentiments', 'moreover', 'do', 'massive', 'military', 'buildup', 'house', 'arrest', 'senior', 'political', 'leaders', 'communications', 'shutdown', 'reveal', 'cynical', 'disregard', 'democratic', 'norms', 'appear', 'current', 'government', 'value', 'jk', 'demonstrative', 'impact', 'rest', 'country', 'place', 'strong', 'nation', 'strong', 'leader', 'show', 'uncompromising', 'political', 'may', 'unintended', 'consequences', 'geographically', 'metaphorically', 'jammu', 'kashmir', 'crown', 'secular', 'india', 'muslim', 'majority', 'region', 'hindu', 'majority', 'country', 'people', 'leaders', 'choose', 'secular', 'india', 'islamic', 'pakistan', 'fact', 'islamists', 'never', 'reconcile', 'bjps', 'adventurous', 'route', 'also', 'backdrop', 'impend', 'us', 'withdrawal', 'afghanistan', 'trigger', 'unforeseeable', 'churn', 'islamist', 'politics', 'region', 'islamists', 'always', 'view', 'kashmir', 'component', 'global', 'grievances', 'whatever', 'intent', 'enable', 'full', 'integration', 'jammu', 'kashmir', 'india', 'mondays', 'decision', 'alter', 'state', 'status', 'could', 'unintended', 'dangerous', 'consequences']\n"
     ]
    }
   ],
   "source": [
    "# Lemmitizing\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    stopwordsNotInArticle[i]=lemmatizer.lemmatize(stopwordsNotInArticle[i],\"v\")\n",
    "print(stopwordsNotInArticle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strongSubjectivtiy(string):\n",
    "\n",
    "    file=open(\"data/bias-lexicon/subjandpolar.txt\",\"r\")\n",
    "\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        for word in words:\n",
    "            if word == string:\n",
    "                #print(\"found\")\n",
    "                #print(words[0] , words[2])\n",
    "                if(words[0]=='type=strongsubj'):\n",
    "                    return True\n",
    "    return False\n",
    "    file.close()\n",
    "\n",
    "string=\"abuse\"\n",
    "strongSubjectivtiy(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def strongSubjectivityContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(strongSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(strongSubjectivityContext(stopwordsNotInArticle,stopwordsNotInArticle[4],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weakSubjectivtiy(string):\n",
    "\n",
    "    file=open(\"data/bias-lexicon/subjandpolar.txt\",\"r\")\n",
    "\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        for word in words:\n",
    "            if word == string:\n",
    "                #print(\"found\")\n",
    "                #print(words[0] , words[2])\n",
    "                if(words[0]=='type=weaksubj'):\n",
    "                    return True\n",
    "    return False\n",
    "    file.close()\n",
    "\n",
    "string=\"abate\"\n",
    "weakSubjectivtiy(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def weakSubjectivityContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(weakSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(weakSubjectivityContext(stopwordsNotInArticle,stopwordsNotInArticle[22],22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def biasLexion(string):\n",
    "\n",
    "    file=open(\"data/bias-lexicon/bias-lexicon.txt\",\"r\")\n",
    "\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        for word in words:\n",
    "            if word == string:\n",
    "                #print(word)\n",
    "                #print(words[0] , words[2])\n",
    "                return True\n",
    "    return False\n",
    "    file.close()\n",
    "\n",
    "string=\"west\"\n",
    "biasLexion(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "22\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def positivewords(string):\n",
    "    \n",
    "    file=open(\"data/bias-lexicon/positive-words.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        positive = False\n",
    "        if words[0] == string:\n",
    "            positive = True\n",
    "            return positive\n",
    "        \n",
    "    return positive\n",
    "    file.close()\n",
    "\n",
    "string=\"accurately\"\n",
    "print(positivewords(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(positivewords(stopwordsNotInArticle[i]))\n",
    "print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def positiveWordContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(positivewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(positiveWordContext(stopwordsNotInArticle,stopwordsNotInArticle[22],22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False]\n",
      "21\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def negativewords(string):\n",
    "    \n",
    "    file=open(\"data/bias-lexicon/negative-words.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        negative = False\n",
    "        if words[0] == string:\n",
    "            negative = True\n",
    "            return negative\n",
    "        \n",
    "    return negative\n",
    "    file.close()\n",
    "string=\"good\"\n",
    "print(negativewords(string))\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(negativewords(stopwordsNotInArticle[i]))\n",
    "print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def negativeWordContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(negativewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(negativeWordContext(stopwordsNotInArticle,stopwordsNotInArticle[17],17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "3\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def factives_hooper(string):\n",
    "    \n",
    "    file=open(\"data/bias-lexicon/factives_hooper1975.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        factives = False\n",
    "        if words[0] == string:\n",
    "            factives = True\n",
    "            return factives\n",
    "        \n",
    "    return factives\n",
    "    file.close()\n",
    "string=\"care\"\n",
    "print(factives_hooper(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(factives_hooper(stopwordsNotInArticle[i]))\n",
    "print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def factives_hooper_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(factives_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(factives_hooper_context(stopwordsNotInArticle,stopwordsNotInArticle[17],17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False]\n",
      "9\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def hedges(string):\n",
    "    file=open(\"data/bias-lexicon/hedges_hyland2005.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        hedge = False\n",
    "        if words[0] == string:\n",
    "            hedge = True\n",
    "            return hedge\n",
    "    return hedge\n",
    "    file.close()\n",
    "string=\"largely\"\n",
    "print(hedges(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(hedges(stopwordsNotInArticle[i]))\n",
    "print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def hedges_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(hedges(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(hedges_context(stopwordsNotInArticle,stopwordsNotInArticle[337],337))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, True, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "22\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def assertive_hooper(string):\n",
    "    file=open(\"data/bias-lexicon/assertives_hooper1975.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        assertives = False\n",
    "        if words[0] == string:\n",
    "            assertives = True\n",
    "            return assertives\n",
    "    return assertives\n",
    "    file.close()\n",
    "string=\"maintain\"\n",
    "print(assertive_hooper(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(assertive_hooper(stopwordsNotInArticle[i]))\n",
    "print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def assertive_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(assertive_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(assertive_context(stopwordsNotInArticle,stopwordsNotInArticle[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, True, False, False, True, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False]\n",
      "36\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def report_verb(string):\n",
    "    file=open(\"data/bias-lexicon/report_verbs.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        report = False\n",
    "        if words[0] == string:\n",
    "            report = True\n",
    "            return report\n",
    "    return report\n",
    "    file.close()\n",
    "string=\"caution\"\n",
    "print(report_verb(string))\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(report_verb(stopwordsNotInArticle[i]))\n",
    "print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def report_verb_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(report_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(report_verb_context(stopwordsNotInArticle,stopwordsNotInArticle[43],43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
      "139\n",
      "248\n",
      "442\n",
      "3\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def implicative_verb(string):\n",
    "    file=open(\"data/bias-lexicon/implicatives_karttunen1971.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        implicative = False\n",
    "        if words[0] == string:\n",
    "            implicative = True\n",
    "            return implicative\n",
    "    return implicative\n",
    "    file.close()\n",
    "string=\"bother\"\n",
    "print(implicative_verb(string))\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(implicative_verb(stopwordsNotInArticle[i]))\n",
    "print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "        print(i)\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def implicative_verb_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(implicative_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(implicative_verb_context(stopwordsNotInArticle,stopwordsNotInArticle[443],443))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
