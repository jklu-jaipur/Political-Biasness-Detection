{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If packages are not found then use: pip install package_name'''\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre processing and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 6)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class dataPreProcessing:\n",
    "    def __init__(self,path):\n",
    "        self.data=pd.read_csv(path,delimiter = \",\",encoding='ISO-8859â€“1')\n",
    "        self.data.columns = ((self.data.columns.str).replace(\"^ \",\"\")).str.replace(\" $\",\"\")   #removing cloumns spaces\n",
    "        self.data[\"Article\"].fillna(\"To be added\", inplace = True)\n",
    "        self.data[\"Headline\"].fillna(\"To be added\", inplace = True)       #replacing NaN values with some text\n",
    "        self.data[\"Label\"].fillna(\"To be added\", inplace = True)\n",
    "        self.data[\"Publisher\"].fillna(\"To be added\", inplace = True)\n",
    "    def read_data(self):\n",
    "        return self.data\n",
    "    def clean_article(self,article):\n",
    "        article=article.lower()\n",
    "        article = re.sub('\\[.*?\\]', '', article)\n",
    "        article = re.sub('[%s]' % re.escape(string.punctuation), '', article)\n",
    "        article = re.sub('\\w*\\d\\w*', '', article)\n",
    "        return article\n",
    "    def clean_dataset(self):\n",
    "        for i in range(len(self.data)):\n",
    "            self.data['Article'][i]=self.clean_article(self.data['Article'][i])\n",
    "            self.data['Headline'][i]=self.clean_article(self.data['Headline'][i])\n",
    "            self.data['Label'][i]=self.data['Label'][i].lower()\n",
    "        return self.data\n",
    "    def tokenize(self):\n",
    "        pass\n",
    "    def remove_stopwords(self):\n",
    "        pass\n",
    "        \n",
    "data = dataPreProcessing('data/Data2.csv')\n",
    "data.read_data().shape           # for comparison of articles\n",
    "#data.read_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a legal dispute dating back to the late  century a question of faith going back even longer and a political issue that has shaped indian politics for three decades were all addressed by the supreme court on saturday when it ruled on the ram janmabhoomibabri masjid issue\n",
      "\n",
      "the court ruled in favour of a temple at ayodhya where many people believe hindu god ram was born but also sought to address what it describes as a wrong committed against muslims especially during the  demolition of a mosque that stood at the disputed site by giving the sunni waqf board five acres elsewhere in ayodhya for a mosque\n",
      "\n",
      "prime minister narendra modi whose bharatiya janata party bjp has had the building of a ram temple at ayodhya as one of the fixtures in its manifesto described the verdict as neither a victory nor a defeat eschewing triumphalism as indeed he has asked his colleagues to mohan bhagwat the supremo of the bjps ideological parent the rashtriya swayamsevak sangh rss which has directly and through its affiliates been at the forefront of the ram janmabhoomi movement echoed that sentiment\n",
      "\n",
      "while theres been some talk but no confirmation of the muslim parties seeking a review most analysts are of the opinion that the courts ruling marks the effective closure of the movement to build a temple as such it is a decision that has national social and political impact\n",
      "\n",
      "at the political level the resolution of the temple issue means that  has seen the end of both mandal and mandir temple issues the first refers to the  implementation of the mandal commissions report reserving  of government jobs and college seats for other backward classes for at least three decades after that the countrys political landscape was largely shaped by mandals biggest beneficiaries it was only the parliamentary elections of  that finally seemed to put the ghost of mandal to rest \n",
      "\n",
      "if mandal gave indias political landscape a clutch of parties that would dominate at least regional politics for three decades the mandir movement gave it the bjp the temple was the singular issue that helped revive the partys fortunes after it slipped to two lok sabha seats in the  parliamentary elections still it was only after narendra modi and amit shah figured out a way to also consolidate the nondominant obc groupings that it really emerged the pole of indian politics\n",
      "the verdict delivered by the supreme court is the beginning of the end of the mandir issue sure its effects will be felt perhaps even in  it is likely that it will take a few years to build the temple which is perfect timing for the next lok sabha polls but not beyond which means  has been a milestone year for the two significant political issues that have pretty much shaped indian politics over the past three decades it is the year one became irrelevant and the other neared if not achieved closure\n",
      "\n",
      "at the national level the overwhelming feeling seems to be one of relief the movement to build a temple has had violent turns in the past including the demolition of the mosque and the nationwide riots that followed india has many pressing issues and cant afford to be held back by such conflicts much though will depend on whether the courts decision encourages the rss and its affiliates to seek similar resolution of other disputes involving places of worship the organisation has said that it will not much also will depend on how the muslim parties to the dispute react to the judgment seeking a review of the decision is within their rights although they must respect the verdict  and they have said that they will a compromise formula agreed to by some of the muslim parties to the dispute has some commonalities with the verdict which means that at least some of them do want to move on\n",
      "\n",
      "at the social level there are two alternative ways to view the verdict one is to see it as a deeply polarising judgment that alienates the countrys muslims some of whom already see themselves being targeted by a state they perceive to be majoritarian the other is to see it as a unifying one which addresses one of the most sticky issues in the country and attempts to strike a balance with that out of the way hindus and muslims could well aspire to arrive at a new equilibrium one that puts the country first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df=data.clean_dataset()['Article'][51]    #for comparison of articles\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing, Lemmatizing, and removing stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparations for the ram mandir bhoomi poojan in ayodhya scheduled for august  are on in full swing with the city being painted in yellow  the colour of knowledge and auspiciousness\n",
      "\n",
      "the prayers and the ceremony are to start tuesday morning with the worship of lord hanumans mark in ayodhya as he is believed to preside over the city the programme was scheduled for sunday but was postponed due to the weekend lockdowns in uttar pradesh amid the coronavirus pandemic\n",
      "\n",
      "continuous akhand ramayan recitation in all local temples and a deepotsava by lighting oil lamps in houses temples and the saryu river on the night of august  and  have been announced\n",
      "\n",
      "\n",
      "an invitation to the programme written in red and black over a yellow background has already been mailed to the guests asking them to be present at karsevakpuram in ayodhya by tuesday  pm for the historical bhoomi poojan the event on wednesday is to be attended by prime minister narendra modi\n",
      "\n",
      "sources close to the shri ram janambhoomi teerth kshetra trust which is the organiser of the event said that the list of more than  invitees has been trimmed to  to ensure social distancing\n",
      "\n",
      "ram mandir bhoomi poojan ram temple bhoomi poojan ayodhya ram temple august  bhoomi poojan pm modi bhoomi poojan ram mandir bhoomi poojan date ram mandir bhoomi poojan time ram mandir bhumi pujan indian express fire brigade personnel sanitise the area near saket degree college ahead of the ground breaking ceremony for the ram temple in ayodhya photo pti\n",
      "the list includes  saints and seers from  spiritual traditions all over the country along with bjp leaders rashtriya swayamsevak sangh rss office bearers and dignitaries connected to the vishva hindu parishad vhp among others\n",
      "\n",
      "a few confirmed names apart from pm modi are up governor anandi ben patel cm yogi adityanath rss chief mohan bhagwat and trust president mahant nritya gopal das\n",
      "\n",
      "on wednesday pm modi is expected to start the event by offering prayers at the famous hanuman garhi temple where he is scheduled to spend no more than seven minutes he is then expected to visit the makeshift ram lalla temple made of wood and glass where he will be given chandan and prasad after he offers flowers to the deity\n",
      "\n",
      "\n",
      "the bhoomi poojan will include chanting of mantras and after shovelling the earth worship of the ground and the shila as per officials in ayodhya a  kg brick made of pure silver will be used for the bhoomi poojan ceremony\n",
      "\n",
      "keeping in mind covid norms arrangements are such that all those attending will sit at a distance of six feet from each other only five people including pm modi anandi ben patel adityanath bhagwat and mahant das are expected to sit on the main stage\n",
      "\n",
      "following the wednesday programme the construction of the temple will begin in full swing members of the trust claim the construction will take between six months and a year\n",
      "489\n",
      "['preparations', 'ram', 'mandir', 'bhoomi', 'poojan', 'ayodhya', 'scheduled', 'august', 'full', 'swing', 'city', 'painted', 'yellow', 'colour', 'knowledge', 'auspiciousness', 'prayers', 'ceremony', 'start', 'tuesday', 'morning', 'worship', 'lord', 'hanumans', 'mark', 'ayodhya', 'believed', 'preside', 'city', 'programme', 'scheduled', 'sunday', 'postponed', 'due', 'weekend', 'lockdowns', 'uttar', 'pradesh', 'amid', 'coronavirus', 'pandemic', 'continuous', 'akhand', 'ramayan', 'recitation', 'local', 'temples', 'deepotsava', 'lighting', 'oil', 'lamps', 'houses', 'temples', 'saryu', 'river', 'night', 'august', 'announced', 'invitation', 'programme', 'written', 'red', 'black', 'yellow', 'background', 'already', 'mailed', 'guests', 'asking', 'present', 'karsevakpuram', 'ayodhya', 'tuesday', 'pm', 'historical', 'bhoomi', 'poojan', 'event', 'wednesday', 'attended', 'prime', 'minister', 'narendra', 'modi', 'sources', 'close', 'shri', 'ram', 'janambhoomi', 'teerth', 'kshetra', 'trust', 'organiser', 'event', 'said', 'list', 'invitees', 'trimmed', 'ensure', 'social', 'distancing', 'ram', 'mandir', 'bhoomi', 'poojan', 'ram', 'temple', 'bhoomi', 'poojan', 'ayodhya', 'ram', 'temple', 'august', 'bhoomi', 'poojan', 'pm', 'modi', 'bhoomi', 'poojan', 'ram', 'mandir', 'bhoomi', 'poojan', 'date', 'ram', 'mandir', 'bhoomi', 'poojan', 'time', 'ram', 'mandir', 'bhumi', 'pujan', 'indian', 'express', 'fire', 'brigade', 'personnel', 'sanitise', 'area', 'near', 'saket', 'degree', 'college', 'ahead', 'ground', 'breaking', 'ceremony', 'ram', 'temple', 'ayodhya', 'photo', 'pti', 'list', 'includes', 'saints', 'seers', 'spiritual', 'traditions', 'country', 'along', 'bjp', 'leaders', 'rashtriya', 'swayamsevak', 'sangh', 'rss', 'office', 'bearers', 'dignitaries', 'connected', 'vishva', 'hindu', 'parishad', 'vhp', 'among', 'others', 'confirmed', 'names', 'apart', 'pm', 'modi', 'governor', 'anandi', 'ben', 'patel', 'cm', 'yogi', 'adityanath', 'rss', 'chief', 'mohan', 'bhagwat', 'trust', 'president', 'mahant', 'nritya', 'gopal', 'das', 'wednesday', 'pm', 'modi', 'expected', 'start', 'event', 'offering', 'prayers', 'famous', 'hanuman', 'garhi', 'temple', 'scheduled', 'spend', 'seven', 'minutes', 'expected', 'visit', 'makeshift', 'ram', 'lalla', 'temple', 'made', 'wood', 'glass', 'given', 'chandan', 'prasad', 'offers', 'flowers', 'deity', 'bhoomi', 'poojan', 'include', 'chanting', 'mantras', 'shovelling', 'earth', 'worship', 'ground', 'shila', 'per', 'officials', 'ayodhya', 'kg', 'brick', 'made', 'pure', 'silver', 'used', 'bhoomi', 'poojan', 'ceremony', 'keeping', 'mind', 'covid', 'norms', 'arrangements', 'attending', 'sit', 'distance', 'six', 'feet', 'five', 'people', 'including', 'pm', 'modi', 'anandi', 'ben', 'patel', 'adityanath', 'bhagwat', 'mahant', 'das', 'expected', 'sit', 'main', 'stage', 'following', 'wednesday', 'programme', 'construction', 'temple', 'begin', 'full', 'swing', 'members', 'trust', 'claim', 'construction', 'take', 'six', 'months', 'year']\n",
      "294\n",
      "['preparations', 'ram', 'mandir', 'bhoomi', 'poojan', 'ayodhya', 'schedule', 'august', 'full', 'swing', 'city', 'paint', 'yellow', 'colour', 'knowledge', 'auspiciousness', 'prayers', 'ceremony', 'start', 'tuesday', 'morning', 'worship', 'lord', 'hanumans', 'mark', 'ayodhya', 'believe', 'preside', 'city', 'programme', 'schedule', 'sunday', 'postpone', 'due', 'weekend', 'lockdowns', 'uttar', 'pradesh', 'amid', 'coronavirus', 'pandemic', 'continuous', 'akhand', 'ramayan', 'recitation', 'local', 'temples', 'deepotsava', 'light', 'oil', 'lamps', 'house', 'temples', 'saryu', 'river', 'night', 'august', 'announce', 'invitation', 'programme', 'write', 'red', 'black', 'yellow', 'background', 'already', 'mail', 'guests', 'ask', 'present', 'karsevakpuram', 'ayodhya', 'tuesday', 'pm', 'historical', 'bhoomi', 'poojan', 'event', 'wednesday', 'attend', 'prime', 'minister', 'narendra', 'modi', 'source', 'close', 'shri', 'ram', 'janambhoomi', 'teerth', 'kshetra', 'trust', 'organiser', 'event', 'say', 'list', 'invite', 'trim', 'ensure', 'social', 'distance', 'ram', 'mandir', 'bhoomi', 'poojan', 'ram', 'temple', 'bhoomi', 'poojan', 'ayodhya', 'ram', 'temple', 'august', 'bhoomi', 'poojan', 'pm', 'modi', 'bhoomi', 'poojan', 'ram', 'mandir', 'bhoomi', 'poojan', 'date', 'ram', 'mandir', 'bhoomi', 'poojan', 'time', 'ram', 'mandir', 'bhumi', 'pujan', 'indian', 'express', 'fire', 'brigade', 'personnel', 'sanitise', 'area', 'near', 'saket', 'degree', 'college', 'ahead', 'grind', 'break', 'ceremony', 'ram', 'temple', 'ayodhya', 'photo', 'pti', 'list', 'include', 'saint', 'seers', 'spiritual', 'traditions', 'country', 'along', 'bjp', 'leaders', 'rashtriya', 'swayamsevak', 'sangh', 'rss', 'office', 'bearers', 'dignitaries', 'connect', 'vishva', 'hindu', 'parishad', 'vhp', 'among', 'others', 'confirm', 'name', 'apart', 'pm', 'modi', 'governor', 'anandi', 'ben', 'patel', 'cm', 'yogi', 'adityanath', 'rss', 'chief', 'mohan', 'bhagwat', 'trust', 'president', 'mahant', 'nritya', 'gopal', 'das', 'wednesday', 'pm', 'modi', 'expect', 'start', 'event', 'offer', 'prayers', 'famous', 'hanuman', 'garhi', 'temple', 'schedule', 'spend', 'seven', 'minutes', 'expect', 'visit', 'makeshift', 'ram', 'lalla', 'temple', 'make', 'wood', 'glass', 'give', 'chandan', 'prasad', 'offer', 'flower', 'deity', 'bhoomi', 'poojan', 'include', 'chant', 'mantras', 'shovel', 'earth', 'worship', 'grind', 'shila', 'per', 'officials', 'ayodhya', 'kg', 'brick', 'make', 'pure', 'silver', 'use', 'bhoomi', 'poojan', 'ceremony', 'keep', 'mind', 'covid', 'norms', 'arrangements', 'attend', 'sit', 'distance', 'six', 'feet', 'five', 'people', 'include', 'pm', 'modi', 'anandi', 'ben', 'patel', 'adityanath', 'bhagwat', 'mahant', 'das', 'expect', 'sit', 'main', 'stage', 'follow', 'wednesday', 'programme', 'construction', 'temple', 'begin', 'full', 'swing', 'members', 'trust', 'claim', 'construction', 'take', 'six', 'months', 'year']\n"
     ]
    }
   ],
   "source": [
    "#tokenize, lemmatize, remove stop-words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "df=data.clean_dataset()['Article'][49]    #for comparison of articles\n",
    "print(df)\n",
    "\n",
    "tokens=word_tokenize(df)\n",
    "#print(tokens)\n",
    "wordsInArticle= len(tokens)\n",
    "print(wordsInArticle)\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    stopwordsInArticle=[]\n",
    "    stopwordsNotInArticle=[]\n",
    "    for i in tokens:\n",
    "        if i not in stopwords.words('english'):\n",
    "            stopwordsNotInArticle.append(i)\n",
    "        else:\n",
    "            stopwordsInArticle.append(i)\n",
    "    return stopwordsInArticle,stopwordsNotInArticle\n",
    "\n",
    "stopwordsInArticle,stopwordsNotInArticle=remove_stop_words(tokens)\n",
    "print(stopwordsNotInArticle)\n",
    "\n",
    "wordsInArticle= len(stopwordsNotInArticle)\n",
    "print(wordsInArticle)\n",
    "\n",
    "def lemmatise(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i]=lemmatizer.lemmatize(tokens[i],\"v\")\n",
    "    return tokens\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    stopwordsNotInArticle[i]=lemmatizer.lemmatize(stopwordsNotInArticle[i],\"v\")    #reduce the word to its infinitive form\n",
    "print(stopwordsNotInArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['legal', 'dispute', 'date', 'back', 'late', 'century', 'question', 'faith', 'go', 'back', 'even', 'longer', 'political', 'issue', 'shape', 'indian', 'politics', 'three', 'decades', 'address', 'supreme', 'court', 'saturday', 'rule', 'ram', 'janmabhoomibabri', 'masjid', 'issue', 'court', 'rule', 'favour', 'temple', 'ayodhya', 'many', 'people', 'believe', 'hindu', 'god', 'ram', 'bear', 'also', 'seek', 'address', 'describe', 'wrong', 'commit', 'muslims', 'especially', 'demolition', 'mosque', 'stand', 'dispute', 'site', 'give', 'sunni', 'waqf', 'board', 'five', 'acres', 'elsewhere', 'ayodhya', 'mosque', 'prime', 'minister', 'narendra', 'modi', 'whose', 'bharatiya', 'janata', 'party', 'bjp', 'build', 'ram', 'temple', 'ayodhya', 'one', 'fixtures', 'manifesto', 'describe', 'verdict', 'neither', 'victory', 'defeat', 'eschew', 'triumphalism', 'indeed', 'ask', 'colleagues', 'mohan', 'bhagwat', 'supremo', 'bjps', 'ideological', 'parent', 'rashtriya', 'swayamsevak', 'sangh', 'rss', 'directly', 'affiliate', 'forefront', 'ram', 'janmabhoomi', 'movement', 'echo', 'sentiment', 'theres', 'talk', 'confirmation', 'muslim', 'party', 'seek', 'review', 'analysts', 'opinion', 'court', 'rule', 'mark', 'effective', 'closure', 'movement', 'build', 'temple', 'decision', 'national', 'social', 'political', 'impact', 'political', 'level', 'resolution', 'temple', 'issue', 'mean', 'see', 'end', 'mandal', 'mandir', 'temple', 'issue', 'first', 'refer', 'implementation', 'mandal', 'commission', 'report', 'reserve', 'government', 'job', 'college', 'seat', 'backward', 'class', 'least', 'three', 'decades', 'countrys', 'political', 'landscape', 'largely', 'shape', 'mandals', 'biggest', 'beneficiaries', 'parliamentary', 'elections', 'finally', 'seem', 'put', 'ghost', 'mandal', 'rest', 'mandal', 'give', 'indias', 'political', 'landscape', 'clutch', 'party', 'would', 'dominate', 'least', 'regional', 'politics', 'three', 'decades', 'mandir', 'movement', 'give', 'bjp', 'temple', 'singular', 'issue', 'help', 'revive', 'party', 'fortunes', 'slip', 'two', 'lok', 'sabha', 'seat', 'parliamentary', 'elections', 'still', 'narendra', 'modi', 'amit', 'shah', 'figure', 'way', 'also', 'consolidate', 'nondominant', 'obc', 'group', 'really', 'emerge', 'pole', 'indian', 'politics', 'verdict', 'deliver', 'supreme', 'court', 'begin', 'end', 'mandir', 'issue', 'sure', 'effect', 'felt', 'perhaps', 'even', 'likely', 'take', 'years', 'build', 'temple', 'perfect', 'time', 'next', 'lok', 'sabha', 'poll', 'beyond', 'mean', 'milestone', 'year', 'two', 'significant', 'political', 'issue', 'pretty', 'much', 'shape', 'indian', 'politics', 'past', 'three', 'decades', 'year', 'one', 'become', 'irrelevant', 'near', 'achieve', 'closure', 'national', 'level', 'overwhelm', 'feel', 'seem', 'one', 'relief', 'movement', 'build', 'temple', 'violent', 'turn', 'past', 'include', 'demolition', 'mosque', 'nationwide', 'riot', 'follow', 'india', 'many', 'press', 'issue', 'cant', 'afford', 'hold', 'back', 'conflict', 'much', 'though', 'depend', 'whether', 'court', 'decision', 'encourage', 'rss', 'affiliate', 'seek', 'similar', 'resolution', 'dispute', 'involve', 'place', 'worship', 'organisation', 'say', 'much', 'also', 'depend', 'muslim', 'party', 'dispute', 'react', 'judgment', 'seek', 'review', 'decision', 'within', 'right', 'although', 'must', 'respect', 'verdict', 'say', 'compromise', 'formula', 'agree', 'muslim', 'party', 'dispute', 'commonalities', 'verdict', 'mean', 'least', 'want', 'move', 'social', 'level', 'two', 'alternative', 'ways', 'view', 'verdict', 'one', 'see', 'deeply', 'polarise', 'judgment', 'alienate', 'countrys', 'muslims', 'already', 'see', 'target', 'state', 'perceive', 'majoritarian', 'see', 'unify', 'one', 'address', 'one', 'sticky', 'issue', 'country', 'attempt', 'strike', 'balance', 'way', 'hindus', 'muslims', 'could', 'well', 'aspire', 'arrive', 'new', 'equilibrium', 'one', 'put', 'country', 'first']\n"
     ]
    }
   ],
   "source": [
    "article=data.clean_dataset()['Article'][51]\n",
    "tokens=word_tokenize(article)\n",
    "stopwordsInArticle,stopwordsNotInArticle=remove_stop_words(tokens)\n",
    "stopwordsNotInArticle=lemmatise(stopwordsNotInArticle)\n",
    "print(stopwordsNotInArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strongSubjectivtiy(string):\n",
    "\n",
    "    file=open(\"data/bias-lexicon/subjandpolar.txt\",\"r\")\n",
    "\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        for word in words:\n",
    "            if word == string:\n",
    "                #print(\"found\")\n",
    "                #print(words[0] , words[2])\n",
    "                if(words[0]=='type=strongsubj'):\n",
    "                    return True\n",
    "    return False\n",
    "    file.close()\n",
    "\n",
    "string=\"abuse\"\n",
    "strongSubjectivtiy(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def strongSubjectivityContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(strongSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(strongSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(strongSubjectivityContext(stopwordsNotInArticle,stopwordsNotInArticle[4],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weakSubjectivtiy(string):\n",
    "\n",
    "    file=open(\"data/bias-lexicon/subjandpolar.txt\",\"r\")\n",
    "\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        for word in words:\n",
    "            if word == string:\n",
    "                #print(\"found\")\n",
    "                #print(words[0] , words[2])\n",
    "                if(words[0]=='type=weaksubj'):\n",
    "                    return True\n",
    "    return False\n",
    "    file.close()\n",
    "\n",
    "string=\"abate\"\n",
    "weakSubjectivtiy(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def weakSubjectivityContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(weakSubjectivtiy(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(weakSubjectivtiy(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(weakSubjectivityContext(stopwordsNotInArticle,stopwordsNotInArticle[22],22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def biasLexion(string):\n",
    "\n",
    "    file=open(\"data/bias-lexicon/bias-lexicon.txt\",\"r\")\n",
    "\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        for word in words:\n",
    "            if word == string:\n",
    "                #print(word)\n",
    "                #print(words[0] , words[2])\n",
    "                return True\n",
    "    return False\n",
    "    file.close()\n",
    "\n",
    "string=\"west\"\n",
    "biasLexion(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "22\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def positivewords(string):\n",
    "    \n",
    "    file=open(\"data/bias-lexicon/positive-words.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        positive = False\n",
    "        if words[0] == string:\n",
    "            positive = True\n",
    "            return positive\n",
    "        \n",
    "    return positive\n",
    "    file.close()\n",
    "\n",
    "string=\"accurately\"\n",
    "print(positivewords(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(positivewords(stopwordsNotInArticle[i]))\n",
    "#print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def positiveWordContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(positivewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(positivewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(positiveWordContext(stopwordsNotInArticle,stopwordsNotInArticle[22],22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "21\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def negativewords(string):\n",
    "    \n",
    "    file=open(\"data/bias-lexicon/negative-words.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        negative = False\n",
    "        if words[0] == string:\n",
    "            negative = True\n",
    "            return negative\n",
    "        \n",
    "    return negative\n",
    "    file.close()\n",
    "string=\"good\"\n",
    "print(negativewords(string))\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(negativewords(stopwordsNotInArticle[i]))\n",
    "#print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def negativeWordContext(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(negativewords(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(negativewords(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(negativeWordContext(stopwordsNotInArticle,stopwordsNotInArticle[17],17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def factives_hooper(string):\n",
    "    \n",
    "    file=open(\"data/bias-lexicon/factives_hooper1975.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        factives = False\n",
    "        if words[0] == string:\n",
    "            factives = True\n",
    "            return factives\n",
    "        \n",
    "    return factives\n",
    "    file.close()\n",
    "string=\"care\"\n",
    "print(factives_hooper(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(factives_hooper(stopwordsNotInArticle[i]))\n",
    "#print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def factives_hooper_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(factives_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(factives_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(factives_hooper_context(stopwordsNotInArticle,stopwordsNotInArticle[17],17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "9\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def hedges(string):\n",
    "    file=open(\"data/bias-lexicon/hedges_hyland2005.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        hedge = False\n",
    "        if words[0] == string:\n",
    "            hedge = True\n",
    "            return hedge\n",
    "    return hedge\n",
    "    file.close()\n",
    "string=\"largely\"\n",
    "print(hedges(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(hedges(stopwordsNotInArticle[i]))\n",
    "#print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def hedges_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(hedges(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(hedges(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(hedges_context(stopwordsNotInArticle,stopwordsNotInArticle[337],337))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "22\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def assertive_hooper(string):\n",
    "    file=open(\"data/bias-lexicon/assertives_hooper1975.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        assertives = False\n",
    "        if words[0] == string:\n",
    "            assertives = True\n",
    "            return assertives\n",
    "    return assertives\n",
    "    file.close()\n",
    "string=\"maintain\"\n",
    "print(assertive_hooper(string))\n",
    "\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(assertive_hooper(stopwordsNotInArticle[i]))\n",
    "#print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def assertive_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(assertive_hooper(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(assertive_hooper(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(assertive_context(stopwordsNotInArticle,stopwordsNotInArticle[0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "36\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def report_verb(string):\n",
    "    file=open(\"data/bias-lexicon/report_verbs.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        report = False\n",
    "        if words[0] == string:\n",
    "            report = True\n",
    "            return report\n",
    "    return report\n",
    "    file.close()\n",
    "string=\"caution\"\n",
    "print(report_verb(string))\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(report_verb(stopwordsNotInArticle[i]))\n",
    "#print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def report_verb_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(report_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(report_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(report_verb_context(stopwordsNotInArticle,stopwordsNotInArticle[43],43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "490\n"
     ]
    }
   ],
   "source": [
    "def implicative_verb(string):\n",
    "    file=open(\"data/bias-lexicon/implicatives_karttunen1971.txt\",\"r\")\n",
    "    for line in file:\n",
    "        words=line.split()\n",
    "        implicative = False\n",
    "        if words[0] == string:\n",
    "            implicative = True\n",
    "            return implicative\n",
    "    return implicative\n",
    "    file.close()\n",
    "string=\"bother\"\n",
    "print(implicative_verb(string))\n",
    "\n",
    "count=[]\n",
    "for i in range(len(stopwordsNotInArticle)):\n",
    "    count.append(implicative_verb(stopwordsNotInArticle[i]))\n",
    "#print(count)\n",
    "true=[]\n",
    "for i in range(len(count)):\n",
    "    if count[i]==True:\n",
    "        true.append(count[i])\n",
    "true\n",
    "print(len(true))\n",
    "print(len(stopwordsNotInArticle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def implicative_verb_context(article,word,index):\n",
    "    length=len(article)-1\n",
    "    flag=False\n",
    "    if index==0:\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==1:\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length:\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index==length-1:\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    if index>1 and index<length-1:\n",
    "        if(implicative_verb(article[index-2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index-1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+1])):\n",
    "            flag=True\n",
    "            return flag\n",
    "        if(implicative_verb(article[index+2])):\n",
    "            flag=True\n",
    "            return flag\n",
    "    return flag\n",
    "\n",
    "print(implicative_verb_context(stopwordsNotInArticle,stopwordsNotInArticle[443],443))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos(string):\n",
    "    tagged = nltk.pos_tag([string])\n",
    "    #print(tagged[0][1])\n",
    "    return tagged[0][1]\n",
    "    \n",
    "def posNeg1(article,index):\n",
    "    if index==0:\n",
    "        return 'none'\n",
    "    else:\n",
    "        string=article[index-1]\n",
    "        tagged = nltk.pos_tag([string])\n",
    "        return tagged[0][1]\n",
    "    \n",
    "def posNeg2(article,index):\n",
    "    if index==0 or index==1:\n",
    "        return 'none'\n",
    "    else:\n",
    "        string=article[index-2]\n",
    "        tagged = nltk.pos_tag([string])\n",
    "        return tagged[0][1]\n",
    "def pos1(article,index):\n",
    "    length=len(article)-1\n",
    "    if index==length:\n",
    "        return 'none'\n",
    "    else:\n",
    "        string=article[index+1]\n",
    "        tagged = nltk.pos_tag([string])\n",
    "        return tagged[0][1]\n",
    "def pos2(article,index):\n",
    "    length=len(article)-1\n",
    "    if index==length or index==length-1:\n",
    "        return 'none'\n",
    "    else:\n",
    "        string=article[index+1]\n",
    "        tagged = nltk.pos_tag([string])\n",
    "        return tagged[0][1]\n",
    "print(len(stopwordsNotInArticle))\n",
    "posNeg2(stopwordsNotInArticle,198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': [],\n",
       " 'POS': [],\n",
       " 'POSNeg1': [],\n",
       " 'POSNeg2': [],\n",
       " 'POS1': [],\n",
       " 'POS2': [],\n",
       " 'Hedge': [],\n",
       " 'HedgeContext': [],\n",
       " 'FativeVerb': [],\n",
       " 'FactiveVerbContext': [],\n",
       " 'AssertiveVerb': [],\n",
       " 'AssertiveVerbContext': [],\n",
       " 'ImplicativeVerb': [],\n",
       " 'ImplicativeVerbContext': [],\n",
       " 'ReportVerb': [],\n",
       " 'ReportVerbContext': [],\n",
       " 'StrongSub': [],\n",
       " 'StrongSubContext': [],\n",
       " 'WeakSub': [],\n",
       " 'WeakSubContext': [],\n",
       " 'PositiveWord': [],\n",
       " 'PositiveWordContext': [],\n",
       " 'NegativeWord': [],\n",
       " 'NegativeWordContext': [],\n",
       " 'BiasLexicon': []}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of Lingusitic features to be considered while analysing a token\n",
    "\n",
    "features = {\n",
    "        'word':[],\n",
    "        'POS':[],\n",
    "        'POSNeg1':[],\n",
    "        'POSNeg2':[],\n",
    "        'POS1':[],\n",
    "        'POS2':[],\n",
    "        'Hedge':[],\n",
    "        'HedgeContext':[],\n",
    "        'FativeVerb':[],\n",
    "        'FactiveVerbContext':[],\n",
    "        'AssertiveVerb':[],\n",
    "        'AssertiveVerbContext':[],\n",
    "        'ImplicativeVerb':[],\n",
    "        'ImplicativeVerbContext':[],\n",
    "        'ReportVerb':[],\n",
    "        'ReportVerbContext':[],\n",
    "        'StrongSub':[],\n",
    "        'StrongSubContext':[],\n",
    "        'WeakSub':[],\n",
    "        'WeakSubContext':[],\n",
    "        'PositiveWord':[],\n",
    "        'PositiveWordContext':[],\n",
    "        'NegativeWord':[],\n",
    "        'NegativeWordContext':[],\n",
    "        'BiasLexicon':[]\n",
    "}\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.read_data().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hedge': [1.8367346938775513, 3.910614525139665, 2.452316076294278, 4.643449419568822, 1.411764705882353], 'HedgeContext': [6.938775510204081, 14.24581005586592, 9.809264305177113, 17.744610281923716, 4.705882352941177], 'FativeVerb': [0.6122448979591837, 0.27932960893854747, 0.544959128065395, 1.8242122719734661, 0.2352941176470588], 'FactiveVerbContext': [2.4489795918367347, 1.1173184357541899, 1.9073569482288828, 7.131011608623548, 0.9411764705882352], 'AssertiveVerb': [4.489795918367347, 3.072625698324022, 4.35967302452316, 5.970149253731343, 3.294117647058824], 'AssertiveVerbContext': [17.346938775510203, 12.290502793296088, 17.166212534059948, 22.553897180762853, 11.76470588235294], 'ImplicativeVerb': [0.6122448979591837, 1.1173184357541899, 0.8174386920980926, 0.4975124378109453, 0.9411764705882352], 'ImplicativeVerbContext': [2.4489795918367347, 4.4692737430167595, 3.2697547683923704, 1.8242122719734661, 3.7647058823529407], 'ReportVerb': [7.346938775510205, 6.145251396648044, 4.632152588555858, 7.960199004975125, 6.8235294117647065], 'ReportVerbContext': [27.55102040816326, 22.62569832402235, 18.256130790190735, 28.192371475953564, 24.0], 'StrongSub': [8.979591836734693, 8.659217877094973, 13.079019073569482, 10.281923714759536, 8.0], 'StrongSubContext': [29.38775510204082, 29.329608938547487, 39.23705722070845, 32.66998341625207, 28.705882352941174], 'WeakSub': [12.857142857142856, 20.11173184357542, 21.525885558583106, 17.24709784411277, 14.823529411764705], 'WeakSubContext': [40.816326530612244, 60.05586592178771, 61.58038147138964, 51.741293532338304, 46.588235294117645], 'PositiveWord': [4.489795918367347, 5.027932960893855, 4.632152588555858, 4.1459369817578775, 4.235294117647059], 'PositiveWordContext': [16.53061224489796, 17.039106145251395, 15.531335149863759, 15.091210613598674, 15.764705882352942], 'NegativeWord': [4.285714285714286, 2.5139664804469275, 10.08174386920981, 5.638474295190713, 4.705882352941177], 'NegativeWordContext': [15.918367346938775, 9.217877094972067, 32.42506811989101, 20.8955223880597, 17.88235294117647], 'BiasLexicon': [24.897959183673468, 24.022346368715084, 25.340599455040874, 29.684908789386398, 26.35294117647059]}\n"
     ]
    }
   ],
   "source": [
    "'''for i in range(data.read_data().shape[0]):\n",
    "    article=data.clean_dataset()['Article'][i]'''\n",
    "result={\n",
    "        'Hedge':[],\n",
    "        'HedgeContext':[],\n",
    "        'FativeVerb':[],\n",
    "        'FactiveVerbContext':[],\n",
    "        'AssertiveVerb':[],\n",
    "        'AssertiveVerbContext':[],\n",
    "        'ImplicativeVerb':[],\n",
    "        'ImplicativeVerbContext':[],\n",
    "        'ReportVerb':[],\n",
    "        'ReportVerbContext':[],\n",
    "        'StrongSub':[],\n",
    "        'StrongSubContext':[],\n",
    "        'WeakSub':[],\n",
    "        'WeakSubContext':[],\n",
    "        'PositiveWord':[],\n",
    "        'PositiveWordContext':[],\n",
    "        'NegativeWord':[],\n",
    "        'NegativeWordContext':[],\n",
    "        'BiasLexicon':[]\n",
    "}\n",
    "for j in range(data.read_data().shape[0]):\n",
    "    #data.clean_dataset()['Article'][i]\n",
    "    article=data.clean_dataset()['Article'][j]\n",
    "    tokens=word_tokenize(article)\n",
    "    stopwordsInArticle,stopwordsNotInArticle=remove_stop_words(tokens)\n",
    "    stopwordsNotInArticle=lemmatise(stopwordsNotInArticle)\n",
    "    features = {\n",
    "            'word':[],\n",
    "            'POS':[],\n",
    "            'POSNeg1':[],\n",
    "            'POSNeg2':[],\n",
    "            'POS1':[],\n",
    "            'POS2':[],\n",
    "            'Hedge':[],\n",
    "            'HedgeContext':[],\n",
    "            'FativeVerb':[],\n",
    "            'FactiveVerbContext':[],\n",
    "            'AssertiveVerb':[],\n",
    "            'AssertiveVerbContext':[],\n",
    "            'ImplicativeVerb':[],\n",
    "            'ImplicativeVerbContext':[],\n",
    "            'ReportVerb':[],\n",
    "            'ReportVerbContext':[],\n",
    "            'StrongSub':[],\n",
    "            'StrongSubContext':[],\n",
    "            'WeakSub':[],\n",
    "            'WeakSubContext':[],\n",
    "            'PositiveWord':[],\n",
    "            'PositiveWordContext':[],\n",
    "            'NegativeWord':[],\n",
    "            'NegativeWordContext':[],\n",
    "            'BiasLexicon':[]\n",
    "    }\n",
    "\n",
    "    for i in range(len(stopwordsNotInArticle)):\n",
    "        features['word'].append(stopwordsNotInArticle[i])\n",
    "        features['POS'].append(pos(stopwordsNotInArticle[i]))\n",
    "        features['POSNeg1'].append(posNeg1(stopwordsNotInArticle,i))\n",
    "        features['POSNeg2'].append(posNeg2(stopwordsNotInArticle,i))\n",
    "        features['POS1'].append(pos1(stopwordsNotInArticle,i))\n",
    "        features['POS2'].append(pos2(stopwordsNotInArticle,i))\n",
    "        features['Hedge'].append(hedges(stopwordsNotInArticle[i]))\n",
    "        features['HedgeContext'].append(hedges_context(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['FativeVerb'].append(factives_hooper(stopwordsNotInArticle[i]))\n",
    "        features['FactiveVerbContext'].append(factives_hooper_context(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['AssertiveVerb'].append(assertive_hooper(stopwordsNotInArticle[i]))\n",
    "        features['AssertiveVerbContext'].append(assertive_context(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['ImplicativeVerb'].append(implicative_verb(stopwordsNotInArticle[i]))\n",
    "        features['ImplicativeVerbContext'].append(implicative_verb_context(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['ReportVerb'].append(report_verb(stopwordsNotInArticle[i]))\n",
    "        features['ReportVerbContext'].append(report_verb_context(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['StrongSub'].append(strongSubjectivtiy(stopwordsNotInArticle[i]))\n",
    "        features['StrongSubContext'].append(strongSubjectivityContext(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['WeakSub'].append(weakSubjectivtiy(stopwordsNotInArticle[i]))\n",
    "        features['WeakSubContext'].append(weakSubjectivityContext(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['PositiveWord'].append(positivewords(stopwordsNotInArticle[i]))\n",
    "        features['PositiveWordContext'].append(positiveWordContext(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['NegativeWord'].append(negativewords(stopwordsNotInArticle[i]))\n",
    "        features['NegativeWordContext'].append(negativeWordContext(stopwordsNotInArticle,stopwordsNotInArticle[i],i))\n",
    "        features['BiasLexicon'].append(biasLexion(stopwordsNotInArticle[i]))\n",
    "\n",
    "    #features\n",
    "    df = pd.DataFrame(features, columns = [\n",
    "            'word',\n",
    "            'POS',\n",
    "            'POSNeg1',\n",
    "            'POSNeg2',\n",
    "            'POS1',\n",
    "            'POS2',\n",
    "            'Hedge',\n",
    "            'HedgeContext',\n",
    "            'FativeVerb',\n",
    "            'FactiveVerbContext',\n",
    "            'AssertiveVerb',\n",
    "            'AssertiveVerbContext',\n",
    "            'ImplicativeVerb',\n",
    "            'ImplicativeVerbContext',\n",
    "            'ReportVerb',\n",
    "            'ReportVerbContext',\n",
    "            'StrongSub',\n",
    "            'StrongSubContext',\n",
    "            'WeakSub',\n",
    "            'WeakSubContext',\n",
    "            'PositiveWord',\n",
    "            'PositiveWordContext',\n",
    "            'NegativeWord',\n",
    "            'NegativeWordContext',\n",
    "            'BiasLexicon']\n",
    "            )\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col!='word' and col!='POS' and col!='POSNeg1' and col!='POSNeg2' and col!='POS1' and col!='POS2':\n",
    "            df[col]=df[col]*1\n",
    "    r,c = df.shape\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col!='word' and col!='POS' and col!='POSNeg1' and col!='POSNeg2' and col!='POS1' and col!='POS2':\n",
    "            result[col].append((df[col].sum()/r)*100)\n",
    "            \n",
    "            \n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hedge</th>\n",
       "      <th>HedgeContext</th>\n",
       "      <th>FativeVerb</th>\n",
       "      <th>FactiveVerbContext</th>\n",
       "      <th>AssertiveVerb</th>\n",
       "      <th>AssertiveVerbContext</th>\n",
       "      <th>ImplicativeVerb</th>\n",
       "      <th>ImplicativeVerbContext</th>\n",
       "      <th>ReportVerb</th>\n",
       "      <th>ReportVerbContext</th>\n",
       "      <th>StrongSub</th>\n",
       "      <th>StrongSubContext</th>\n",
       "      <th>WeakSub</th>\n",
       "      <th>WeakSubContext</th>\n",
       "      <th>PositiveWord</th>\n",
       "      <th>PositiveWordContext</th>\n",
       "      <th>NegativeWord</th>\n",
       "      <th>NegativeWordContext</th>\n",
       "      <th>BiasLexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.836735</td>\n",
       "      <td>6.938776</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>2.448980</td>\n",
       "      <td>4.489796</td>\n",
       "      <td>17.346939</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>2.448980</td>\n",
       "      <td>7.346939</td>\n",
       "      <td>27.551020</td>\n",
       "      <td>8.979592</td>\n",
       "      <td>29.387755</td>\n",
       "      <td>12.857143</td>\n",
       "      <td>40.816327</td>\n",
       "      <td>4.489796</td>\n",
       "      <td>16.530612</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>15.918367</td>\n",
       "      <td>24.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.910615</td>\n",
       "      <td>14.245810</td>\n",
       "      <td>0.279330</td>\n",
       "      <td>1.117318</td>\n",
       "      <td>3.072626</td>\n",
       "      <td>12.290503</td>\n",
       "      <td>1.117318</td>\n",
       "      <td>4.469274</td>\n",
       "      <td>6.145251</td>\n",
       "      <td>22.625698</td>\n",
       "      <td>8.659218</td>\n",
       "      <td>29.329609</td>\n",
       "      <td>20.111732</td>\n",
       "      <td>60.055866</td>\n",
       "      <td>5.027933</td>\n",
       "      <td>17.039106</td>\n",
       "      <td>2.513966</td>\n",
       "      <td>9.217877</td>\n",
       "      <td>24.022346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.452316</td>\n",
       "      <td>9.809264</td>\n",
       "      <td>0.544959</td>\n",
       "      <td>1.907357</td>\n",
       "      <td>4.359673</td>\n",
       "      <td>17.166213</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>3.269755</td>\n",
       "      <td>4.632153</td>\n",
       "      <td>18.256131</td>\n",
       "      <td>13.079019</td>\n",
       "      <td>39.237057</td>\n",
       "      <td>21.525886</td>\n",
       "      <td>61.580381</td>\n",
       "      <td>4.632153</td>\n",
       "      <td>15.531335</td>\n",
       "      <td>10.081744</td>\n",
       "      <td>32.425068</td>\n",
       "      <td>25.340599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.643449</td>\n",
       "      <td>17.744610</td>\n",
       "      <td>1.824212</td>\n",
       "      <td>7.131012</td>\n",
       "      <td>5.970149</td>\n",
       "      <td>22.553897</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>1.824212</td>\n",
       "      <td>7.960199</td>\n",
       "      <td>28.192371</td>\n",
       "      <td>10.281924</td>\n",
       "      <td>32.669983</td>\n",
       "      <td>17.247098</td>\n",
       "      <td>51.741294</td>\n",
       "      <td>4.145937</td>\n",
       "      <td>15.091211</td>\n",
       "      <td>5.638474</td>\n",
       "      <td>20.895522</td>\n",
       "      <td>29.684909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.411765</td>\n",
       "      <td>4.705882</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>3.764706</td>\n",
       "      <td>6.823529</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.705882</td>\n",
       "      <td>14.823529</td>\n",
       "      <td>46.588235</td>\n",
       "      <td>4.235294</td>\n",
       "      <td>15.764706</td>\n",
       "      <td>4.705882</td>\n",
       "      <td>17.882353</td>\n",
       "      <td>26.352941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hedge  HedgeContext  FativeVerb  FactiveVerbContext  AssertiveVerb  \\\n",
       "0  1.836735      6.938776    0.612245            2.448980       4.489796   \n",
       "1  3.910615     14.245810    0.279330            1.117318       3.072626   \n",
       "2  2.452316      9.809264    0.544959            1.907357       4.359673   \n",
       "3  4.643449     17.744610    1.824212            7.131012       5.970149   \n",
       "4  1.411765      4.705882    0.235294            0.941176       3.294118   \n",
       "\n",
       "   AssertiveVerbContext  ImplicativeVerb  ImplicativeVerbContext  ReportVerb  \\\n",
       "0             17.346939         0.612245                2.448980    7.346939   \n",
       "1             12.290503         1.117318                4.469274    6.145251   \n",
       "2             17.166213         0.817439                3.269755    4.632153   \n",
       "3             22.553897         0.497512                1.824212    7.960199   \n",
       "4             11.764706         0.941176                3.764706    6.823529   \n",
       "\n",
       "   ReportVerbContext  StrongSub  StrongSubContext    WeakSub  WeakSubContext  \\\n",
       "0          27.551020   8.979592         29.387755  12.857143       40.816327   \n",
       "1          22.625698   8.659218         29.329609  20.111732       60.055866   \n",
       "2          18.256131  13.079019         39.237057  21.525886       61.580381   \n",
       "3          28.192371  10.281924         32.669983  17.247098       51.741294   \n",
       "4          24.000000   8.000000         28.705882  14.823529       46.588235   \n",
       "\n",
       "   PositiveWord  PositiveWordContext  NegativeWord  NegativeWordContext  \\\n",
       "0      4.489796            16.530612      4.285714            15.918367   \n",
       "1      5.027933            17.039106      2.513966             9.217877   \n",
       "2      4.632153            15.531335     10.081744            32.425068   \n",
       "3      4.145937            15.091211      5.638474            20.895522   \n",
       "4      4.235294            15.764706      4.705882            17.882353   \n",
       "\n",
       "   BiasLexicon  \n",
       "0    24.897959  \n",
       "1    24.022346  \n",
       "2    25.340599  \n",
       "3    29.684909  \n",
       "4    26.352941  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame(result, columns = [\n",
    "        'Hedge',\n",
    "        'HedgeContext',\n",
    "        'FativeVerb',\n",
    "        'FactiveVerbContext',\n",
    "        'AssertiveVerb',\n",
    "        'AssertiveVerbContext',\n",
    "        'ImplicativeVerb',\n",
    "        'ImplicativeVerbContext',\n",
    "        'ReportVerb',\n",
    "        'ReportVerbContext',\n",
    "        'StrongSub',\n",
    "        'StrongSubContext',\n",
    "        'WeakSub',\n",
    "        'WeakSubContext',\n",
    "        'PositiveWord',\n",
    "        'PositiveWordContext',\n",
    "        'NegativeWord',\n",
    "        'NegativeWordContext',\n",
    "        'BiasLexicon']\n",
    "        )\n",
    "df_result.to_csv('result.csv')\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>POSNeg1</th>\n",
       "      <th>POSNeg2</th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>Hedge</th>\n",
       "      <th>HedgeContext</th>\n",
       "      <th>FativeVerb</th>\n",
       "      <th>FactiveVerbContext</th>\n",
       "      <th>...</th>\n",
       "      <th>ReportVerbContext</th>\n",
       "      <th>StrongSub</th>\n",
       "      <th>StrongSubContext</th>\n",
       "      <th>WeakSub</th>\n",
       "      <th>WeakSubContext</th>\n",
       "      <th>PositiveWord</th>\n",
       "      <th>PositiveWordContext</th>\n",
       "      <th>NegativeWord</th>\n",
       "      <th>NegativeWordContext</th>\n",
       "      <th>BiasLexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>preparations</td>\n",
       "      <td>NNS</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ram</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>none</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mandir</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bhoomi</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>poojan</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>construction</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>take</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>six</td>\n",
       "      <td>CD</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>months</td>\n",
       "      <td>NNS</td>\n",
       "      <td>CD</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>year</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>CD</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  POS POSNeg1 POSNeg2  POS1  POS2  Hedge  HedgeContext  \\\n",
       "0    preparations  NNS    none    none    NN    NN  False         False   \n",
       "1             ram   NN     NNS    none    NN    NN  False         False   \n",
       "2          mandir   NN      NN     NNS    NN    NN  False         False   \n",
       "3          bhoomi   NN      NN      NN    NN    NN  False         False   \n",
       "4          poojan   NN      NN      NN    NN    NN  False         False   \n",
       "..            ...  ...     ...     ...   ...   ...    ...           ...   \n",
       "289  construction   NN      NN      NN    VB    VB  False          True   \n",
       "290          take   VB      NN      NN    CD    CD  False          True   \n",
       "291           six   CD      VB      NN   NNS   NNS  False         False   \n",
       "292        months  NNS      CD      VB    NN  none  False         False   \n",
       "293          year   NN     NNS      CD  none  none  False         False   \n",
       "\n",
       "     FativeVerb  FactiveVerbContext  ...  ReportVerbContext  StrongSub  \\\n",
       "0         False               False  ...              False      False   \n",
       "1         False               False  ...              False      False   \n",
       "2         False               False  ...              False      False   \n",
       "3         False               False  ...              False      False   \n",
       "4         False               False  ...              False      False   \n",
       "..          ...                 ...  ...                ...        ...   \n",
       "289       False               False  ...               True      False   \n",
       "290       False               False  ...               True      False   \n",
       "291       False               False  ...              False      False   \n",
       "292       False               False  ...              False      False   \n",
       "293       False               False  ...              False      False   \n",
       "\n",
       "     StrongSubContext  WeakSub  WeakSubContext  PositiveWord  \\\n",
       "0               False    False           False         False   \n",
       "1               False    False           False         False   \n",
       "2               False    False           False         False   \n",
       "3               False    False           False         False   \n",
       "4               False    False           False         False   \n",
       "..                ...      ...             ...           ...   \n",
       "289             False    False            True         False   \n",
       "290             False    False            True         False   \n",
       "291             False    False           False         False   \n",
       "292             False    False           False         False   \n",
       "293             False    False           False         False   \n",
       "\n",
       "     PositiveWordContext  NegativeWord  NegativeWordContext  BiasLexicon  \n",
       "0                  False         False                False        False  \n",
       "1                  False         False                False        False  \n",
       "2                  False         False                False        False  \n",
       "3                  False         False                False        False  \n",
       "4                  False         False                False        False  \n",
       "..                   ...           ...                  ...          ...  \n",
       "289                 True         False                False        False  \n",
       "290                False         False                False         True  \n",
       "291                False         False                False        False  \n",
       "292                False         False                False        False  \n",
       "293                False         False                False         True  \n",
       "\n",
       "[294 rows x 25 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(features, columns = [\n",
    "        'word',\n",
    "        'POS',\n",
    "        'POSNeg1',\n",
    "        'POSNeg2',\n",
    "        'POS1',\n",
    "        'POS2',\n",
    "        'Hedge',\n",
    "        'HedgeContext',\n",
    "        'FativeVerb',\n",
    "        'FactiveVerbContext',\n",
    "        'AssertiveVerb',\n",
    "        'AssertiveVerbContext',\n",
    "        'ImplicativeVerb',\n",
    "        'ImplicativeVerbContext',\n",
    "        'ReportVerb',\n",
    "        'ReportVerbContext',\n",
    "        'StrongSub',\n",
    "        'StrongSubContext',\n",
    "        'WeakSub',\n",
    "        'WeakSubContext',\n",
    "        'PositiveWord',\n",
    "        'PositiveWordContext',\n",
    "        'NegativeWord',\n",
    "        'NegativeWordContext',\n",
    "        'BiasLexicon']\n",
    "        )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word                      object\n",
       "POS                       object\n",
       "POSNeg1                   object\n",
       "POSNeg2                   object\n",
       "POS1                      object\n",
       "POS2                      object\n",
       "Hedge                       bool\n",
       "HedgeContext                bool\n",
       "FativeVerb                  bool\n",
       "FactiveVerbContext          bool\n",
       "AssertiveVerb               bool\n",
       "AssertiveVerbContext        bool\n",
       "ImplicativeVerb             bool\n",
       "ImplicativeVerbContext      bool\n",
       "ReportVerb                  bool\n",
       "ReportVerbContext           bool\n",
       "StrongSub                   bool\n",
       "StrongSubContext            bool\n",
       "WeakSub                     bool\n",
       "WeakSubContext              bool\n",
       "PositiveWord                bool\n",
       "PositiveWordContext         bool\n",
       "NegativeWord                bool\n",
       "NegativeWordContext         bool\n",
       "BiasLexicon                 bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to int values\n",
    "\n",
    "'''df['Hedge']=df['Hedge'] * 1\n",
    "df['HedgeContext']=df['HedgeContext'] * 1\n",
    "df['FativeVerb']=df['FativeVerb'] * 1\n",
    "df['FactiveVerbContext']=df['FactiveVerbContext'] * 1\n",
    "df['AssertiveVerb']=df['AssertiveVerb'] * 1\n",
    "df['AssertiveVerbContext']=df['AssertiveVerbContext'] * 1\n",
    "df['ImplicativeVerb']=df['ImplicativeVerb']*1\n",
    "df['ImplicativeVerbContext']=df['ImplicativeVerbContext'] * 1\n",
    "df['ReportVerb']=df['ReportVerb'] * 1\n",
    "df['ReportVerbContext'] = df['ReportVerbContext'] * 1\n",
    "df['StrongSub']=df['StrongSub'] * 1\n",
    "df['StrongSubContext']=df['StrongSubContext'] * 1\n",
    "df['WeakSub'] = df['WeakSub'] * 1\n",
    "df['WeakSubContext'] = df['WeakSubContext'] * 1\n",
    "df['PositiveWord'] = df['PositiveWord'] * 1\n",
    "df['PositiveWordContext'] = df['PositiveWordContext'] * 1\n",
    "df['NegativeWord']  = df['NegativeWord'] * 1\n",
    "df['NegativeWordContext'] = df['NegativeWordContext'] * 1\n",
    "df['BiasLexicon'] = df['BiasLexicon'] * 1'''\n",
    "for col in df.columns:\n",
    "    if col!='word' and col!='POS' and col!='POSNeg1' and col!='POSNeg2' and col!='POS1' and col!='POS2':\n",
    "        df[col]=df[col]*1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word                      object\n",
       "POS                       object\n",
       "POSNeg1                   object\n",
       "POSNeg2                   object\n",
       "POS1                      object\n",
       "POS2                      object\n",
       "Hedge                      int32\n",
       "HedgeContext               int32\n",
       "FativeVerb                 int32\n",
       "FactiveVerbContext         int32\n",
       "AssertiveVerb              int32\n",
       "AssertiveVerbContext       int32\n",
       "ImplicativeVerb            int32\n",
       "ImplicativeVerbContext     int32\n",
       "ReportVerb                 int32\n",
       "ReportVerbContext          int32\n",
       "StrongSub                  int32\n",
       "StrongSubContext           int32\n",
       "WeakSub                    int32\n",
       "WeakSubContext             int32\n",
       "PositiveWord               int32\n",
       "PositiveWordContext        int32\n",
       "NegativeWord               int32\n",
       "NegativeWordContext        int32\n",
       "BiasLexicon                int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>POSNeg1</th>\n",
       "      <th>POSNeg2</th>\n",
       "      <th>POS1</th>\n",
       "      <th>POS2</th>\n",
       "      <th>Hedge</th>\n",
       "      <th>HedgeContext</th>\n",
       "      <th>FativeVerb</th>\n",
       "      <th>FactiveVerbContext</th>\n",
       "      <th>...</th>\n",
       "      <th>ReportVerbContext</th>\n",
       "      <th>StrongSub</th>\n",
       "      <th>StrongSubContext</th>\n",
       "      <th>WeakSub</th>\n",
       "      <th>WeakSubContext</th>\n",
       "      <th>PositiveWord</th>\n",
       "      <th>PositiveWordContext</th>\n",
       "      <th>NegativeWord</th>\n",
       "      <th>NegativeWordContext</th>\n",
       "      <th>BiasLexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>preparations</td>\n",
       "      <td>NNS</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ram</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>none</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mandir</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bhoomi</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>poojan</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>construction</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>take</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>six</td>\n",
       "      <td>CD</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>months</td>\n",
       "      <td>NNS</td>\n",
       "      <td>CD</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>year</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>CD</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  POS POSNeg1 POSNeg2  POS1  POS2  Hedge  HedgeContext  \\\n",
       "0    preparations  NNS    none    none    NN    NN      0             0   \n",
       "1             ram   NN     NNS    none    NN    NN      0             0   \n",
       "2          mandir   NN      NN     NNS    NN    NN      0             0   \n",
       "3          bhoomi   NN      NN      NN    NN    NN      0             0   \n",
       "4          poojan   NN      NN      NN    NN    NN      0             0   \n",
       "..            ...  ...     ...     ...   ...   ...    ...           ...   \n",
       "583  construction   NN      NN      NN    VB    VB      0             1   \n",
       "584          take   VB      NN      NN    CD    CD      0             1   \n",
       "585           six   CD      VB      NN   NNS   NNS      0             0   \n",
       "586        months  NNS      CD      VB    NN  none      0             0   \n",
       "587          year   NN     NNS      CD  none  none      0             0   \n",
       "\n",
       "     FativeVerb  FactiveVerbContext  ...  ReportVerbContext  StrongSub  \\\n",
       "0             0                   0  ...                  0          0   \n",
       "1             0                   0  ...                  0          0   \n",
       "2             0                   0  ...                  0          0   \n",
       "3             0                   0  ...                  0          0   \n",
       "4             0                   0  ...                  0          0   \n",
       "..          ...                 ...  ...                ...        ...   \n",
       "583           0                   0  ...                  1          0   \n",
       "584           0                   0  ...                  1          0   \n",
       "585           0                   0  ...                  0          0   \n",
       "586           0                   0  ...                  0          0   \n",
       "587           0                   0  ...                  0          0   \n",
       "\n",
       "     StrongSubContext  WeakSub  WeakSubContext  PositiveWord  \\\n",
       "0                   0        0               0             0   \n",
       "1                   0        0               0             0   \n",
       "2                   0        0               0             0   \n",
       "3                   0        0               0             0   \n",
       "4                   0        0               0             0   \n",
       "..                ...      ...             ...           ...   \n",
       "583                 0        0               1             0   \n",
       "584                 0        0               1             0   \n",
       "585                 0        0               0             0   \n",
       "586                 0        0               0             0   \n",
       "587                 0        0               0             0   \n",
       "\n",
       "     PositiveWordContext  NegativeWord  NegativeWordContext  BiasLexicon  \n",
       "0                      0             0                    0            0  \n",
       "1                      0             0                    0            0  \n",
       "2                      0             0                    0            0  \n",
       "3                      0             0                    0            0  \n",
       "4                      0             0                    0            0  \n",
       "..                   ...           ...                  ...          ...  \n",
       "583                    1             0                    0            0  \n",
       "584                    0             0                    0            1  \n",
       "585                    0             0                    0            0  \n",
       "586                    0             0                    0            0  \n",
       "587                    0             0                    0            1  \n",
       "\n",
       "[588 rows x 25 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hedge': [0.3401360544217687], 'HedgeContext': [1.3605442176870748], 'FativeVerb': [0.6802721088435374], 'FactiveVerbContext': [2.7210884353741496], 'AssertiveVerb': [2.380952380952381], 'AssertiveVerbContext': [9.523809523809524], 'ImplicativeVerb': [0.3401360544217687], 'ImplicativeVerbContext': [1.3605442176870748], 'ReportVerb': [4.761904761904762], 'ReportVerbContext': [16.666666666666664], 'StrongSub': [2.0408163265306123], 'StrongSubContext': [7.8231292517006805], 'WeakSub': [7.8231292517006805], 'WeakSubContext': [26.190476190476193], 'PositiveWord': [2.380952380952381], 'PositiveWordContext': [9.183673469387756], 'NegativeWord': [1.0204081632653061], 'NegativeWordContext': [3.4013605442176873], 'BiasLexicon': [14.625850340136054]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hedge</th>\n",
       "      <th>HedgeContext</th>\n",
       "      <th>FativeVerb</th>\n",
       "      <th>FactiveVerbContext</th>\n",
       "      <th>AssertiveVerb</th>\n",
       "      <th>AssertiveVerbContext</th>\n",
       "      <th>ImplicativeVerb</th>\n",
       "      <th>ImplicativeVerbContext</th>\n",
       "      <th>ReportVerb</th>\n",
       "      <th>ReportVerbContext</th>\n",
       "      <th>StrongSub</th>\n",
       "      <th>StrongSubContext</th>\n",
       "      <th>WeakSub</th>\n",
       "      <th>WeakSubContext</th>\n",
       "      <th>PositiveWord</th>\n",
       "      <th>PositiveWordContext</th>\n",
       "      <th>NegativeWord</th>\n",
       "      <th>NegativeWordContext</th>\n",
       "      <th>BiasLexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>1.360544</td>\n",
       "      <td>0.680272</td>\n",
       "      <td>2.721088</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>9.52381</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>1.360544</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>2.040816</td>\n",
       "      <td>7.823129</td>\n",
       "      <td>7.823129</td>\n",
       "      <td>26.190476</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>9.183673</td>\n",
       "      <td>1.020408</td>\n",
       "      <td>3.401361</td>\n",
       "      <td>14.62585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hedge  HedgeContext  FativeVerb  FactiveVerbContext  AssertiveVerb  \\\n",
       "0  0.340136      1.360544    0.680272            2.721088       2.380952   \n",
       "\n",
       "   AssertiveVerbContext  ImplicativeVerb  ImplicativeVerbContext  ReportVerb  \\\n",
       "0               9.52381         0.340136                1.360544    4.761905   \n",
       "\n",
       "   ReportVerbContext  StrongSub  StrongSubContext   WeakSub  WeakSubContext  \\\n",
       "0          16.666667   2.040816          7.823129  7.823129       26.190476   \n",
       "\n",
       "   PositiveWord  PositiveWordContext  NegativeWord  NegativeWordContext  \\\n",
       "0      2.380952             9.183673      1.020408             3.401361   \n",
       "\n",
       "   BiasLexicon  \n",
       "0     14.62585  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# some analysis\n",
    "result= {\n",
    "    'Property':[],\n",
    "    'Total':[],\n",
    "    'Percentage':[]\n",
    "}\n",
    "r,c = df.shape\n",
    "for col in df.columns:\n",
    "    if col!='word' and col!='POS' and col!='POSNeg1' and col!='POSNeg2' and col!='POS1' and col!='POS2':\n",
    "        #print(col ,\"            \", df[col].sum(),\"         \", df[col].sum()/r)\n",
    "        result['Property'].append(col)\n",
    "        result['Total'].append(df[col].sum())\n",
    "        result['Percentage'].append((df[col].sum()/r)*100)\n",
    "#print(result)\n",
    "'''\n",
    "r,c = df.shape\n",
    "result={\n",
    "        'Hedge':[],\n",
    "        'HedgeContext':[],\n",
    "        'FativeVerb':[],\n",
    "        'FactiveVerbContext':[],\n",
    "        'AssertiveVerb':[],\n",
    "        'AssertiveVerbContext':[],\n",
    "        'ImplicativeVerb':[],\n",
    "        'ImplicativeVerbContext':[],\n",
    "        'ReportVerb':[],\n",
    "        'ReportVerbContext':[],\n",
    "        'StrongSub':[],\n",
    "        'StrongSubContext':[],\n",
    "        'WeakSub':[],\n",
    "        'WeakSubContext':[],\n",
    "        'PositiveWord':[],\n",
    "        'PositiveWordContext':[],\n",
    "        'NegativeWord':[],\n",
    "        'NegativeWordContext':[],\n",
    "        'BiasLexicon':[]\n",
    "}\n",
    "for col in df.columns:\n",
    "    if col!='word' and col!='POS' and col!='POSNeg1' and col!='POSNeg2' and col!='POS1' and col!='POS2':\n",
    "        result[col].append((df[col].sum()/r)*100)\n",
    "print(result)\n",
    "\n",
    "df = pd.DataFrame(result, columns = [\n",
    "        'Hedge',\n",
    "        'HedgeContext',\n",
    "        'FativeVerb',\n",
    "        'FactiveVerbContext',\n",
    "        'AssertiveVerb',\n",
    "        'AssertiveVerbContext',\n",
    "        'ImplicativeVerb',\n",
    "        'ImplicativeVerbContext',\n",
    "        'ReportVerb',\n",
    "        'ReportVerbContext',\n",
    "        'StrongSub',\n",
    "        'StrongSubContext',\n",
    "        'WeakSub',\n",
    "        'WeakSubContext',\n",
    "        'PositiveWord',\n",
    "        'PositiveWordContext',\n",
    "        'NegativeWord',\n",
    "        'NegativeWordContext',\n",
    "        'BiasLexicon']\n",
    "        )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Hedge',\n",
    "        'HedgeContext',\n",
    "        'FativeVerb',\n",
    "        'FactiveVerbContext',\n",
    "        'AssertiveVerb',\n",
    "        'AssertiveVerbContext',\n",
    "        'ImplicativeVerb',\n",
    "        'ImplicativeVerbContext',\n",
    "        'ReportVerb',\n",
    "        'ReportVerbContext',\n",
    "        'StrongSub',\n",
    "        'StrongSubContext',\n",
    "        'WeakSub',\n",
    "        'WeakSubContext',\n",
    "        'PositiveWord',\n",
    "        'PositiveWordContext',\n",
    "        'NegativeWord',\n",
    "        'NegativeWordContext']]\n",
    "y = df['BiasLexicon']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "y_pred=logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.88        55\n",
      "           1       0.75      0.18      0.29        17\n",
      "\n",
      "    accuracy                           0.79        72\n",
      "   macro avg       0.77      0.58      0.58        72\n",
      "weighted avg       0.78      0.79      0.74        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
